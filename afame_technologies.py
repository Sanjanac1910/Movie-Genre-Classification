# -*- coding: utf-8 -*-
"""Afame Technologies.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oPKCDBPK66khCrYAdEIqDm39wPS-pgT9
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re
import nltk
import string
from nltk.corpus import stopwords
from nltk.stem import LancasterStemmer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report

# Download NLTK data
nltk.download('stopwords')
nltk.download('punkt')

# Step 1: Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Step 2: Define file paths (update these paths as per your Google Drive structure)
train_file_path = '/content/drive/My Drive/colab_notebooks1/train_data.txt'
test_file_path = '/content/drive/My Drive/colab_notebooks1/test_data.txt'

# Step 3: Read and preprocess the data
train_data = pd.read_csv(train_file_path, delimiter=':::', encoding='utf-8', engine='python')
train_data.columns = ['ID', 'TITLE', 'GENRE', 'DESCRIPTION']
print(train_data.describe())

# Combine TITLE and DESCRIPTION for feature extraction
train_data['TEXT'] = train_data['TITLE'] + ' ' + train_data['DESCRIPTION']

# Text preprocessing function
def preprocess_text(text):
    text = text.lower()  # Convert to lowercase
    text = re.sub(f'[{re.escape(string.punctuation)}]', '', text)  # Remove punctuation
    tokens = nltk.word_tokenize(text)  # Tokenize
    tokens = [word for word in tokens if word not in stopwords.words('english')]  # Remove stopwords
    stemmer = LancasterStemmer()
    tokens = [stemmer.stem(word) for word in tokens]  # Stemming
    return ' '.join(tokens)

# Apply text preprocessing
train_data['TEXT'] = train_data['TEXT'].apply(preprocess_text)

# Step 4: Read and parse the test data
with open(test_file_path, 'r', encoding='utf-8') as file:
    test_lines = file.readlines()

test_data = []
for line in test_lines:
    fields = line.strip().split(':::')
    if len(fields) == 3:
        test_data.append(fields)

# Convert test data to DataFrame
test_df = pd.DataFrame(test_data, columns=['ID', 'TITLE', 'DESCRIPTION'])

# Ensure TEXT column is created correctly by combining TITLE and DESCRIPTION if necessary
test_df['TEXT'] = test_df['TITLE'] + ' ' + test_df['DESCRIPTION']

# Apply the same preprocessing to the test data
test_df['TEXT'] = test_df['TEXT'].apply(preprocess_text)

# Print test data in a table format
print(test_df)

# Plot the distribution of genres in the training data
plt.figure(figsize=(12, 6))
sns.countplot(data=train_data, y='GENRE', order=train_data['GENRE'].value_counts().index, palette='viridis')
plt.xlabel('Count', fontsize=14, fontweight='bold')
plt.ylabel('GENRE', fontsize=14, fontweight='bold')

# Plot the distribution of genres using a bar plot
plt.figure(figsize=(12, 6))
counts = train_data['GENRE'].value_counts()
sns.barplot(x=counts.index, y=counts, palette='viridis')
plt.xlabel('GENRE', fontsize=14, fontweight='bold')
plt.ylabel('Count', fontsize=14, fontweight='bold')
plt.title('Distribution of Genres', fontsize=16, fontweight='bold')
plt.xticks(rotation=90, fontsize=14, fontweight='bold')
plt.show()

# TF-IDF Vectorization
tfidf_vectorizer = TfidfVectorizer(max_features=5000)
X = tfidf_vectorizer.fit_transform(train_data['TEXT'])
y = train_data['GENRE']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a Naive Bayes classifier
nb_classifier = MultinomialNB()
nb_classifier.fit(X_train, y_train)

# Predict on the test set
y_pred = nb_classifier.predict(X_test)

# Evaluate the classifier
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy}')
print('Classification Report:')
print(classification_report(y_test, y_pred))

# Step 7: Use the trained model to make predictions on the test data
X_test_transformed = tfidf_vectorizer.transform(test_df['TEXT'])
X_test_predictions = nb_classifier.predict(X_test_transformed)
test_df['Predicted_Genre'] = X_test_predictions

# Save the test_df DataFrame with predicted genres to a CSV file
test_df.to_csv('/content/drive/My Drive/colab_notebooks1/predicted_genres.csv', index=False)

# Display the 'test_df' DataFrame with predicted genres
print(test_df)